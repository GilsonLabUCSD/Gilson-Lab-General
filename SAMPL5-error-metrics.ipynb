{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boostrapping error metrics for SAMPL5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook reads in SAMPL5 submission data, performs bootstrapping on the uncertainties, and plots the results. This file needs the following directory structure and will write pickles of the results if `run_calculation = True` or read pickles of the results if `run_calculation = False`.\n",
    "```    \n",
    ".\n",
    "├── Calc-CB\n",
    "│   ├── BAR-ab-initio.txt\n",
    "│   ├── BAR-dock.txt\n",
    "│   ├── BEDAM.txt\n",
    "│   ├── CBClip-absolute.pickle (will be created if missing)\n",
    "│   ├── MovTyp-1.txt\n",
    "│   ├── MovTyp-2.txt\n",
    "│   ├── Null1.txt\n",
    "│   ├── Null2.txt\n",
    "│   ├── SOMD-1.txt\n",
    "│   ├── SOMD-2.txt\n",
    "│   ├── SOMD-3.txt\n",
    "│   ├── SOMD-4.txt\n",
    "│   ├── TI-ab-initio.txt\n",
    "│   ├── TI-dock.txt\n",
    "│   └── TIxBar.txt\n",
    "├── Calc-OA\n",
    "│   ├── APR-OPC.txt\n",
    "│   ├── APR-TIP3P.txt\n",
    "│   ├── BEDAM.txt\n",
    "│   ├── CCSD(T)-neutral.txt\n",
    "│   ├── DFT-charged.txt\n",
    "│   ├── DFT-neutral.txt\n",
    "│   ├── Metadynamics.txt\n",
    "│   ├── MMPBSA-GAFF.txt\n",
    "│   ├── MMPBSA-OPLS.txt\n",
    "│   ├── MovTyp-1.txt\n",
    "│   ├── MovTyp-2.txt\n",
    "│   ├── Null1.txt\n",
    "│   ├── Null2.txt\n",
    "│   ├── OAH-OAMe-absolute.pickle (will be created if missing)\n",
    "│   ├── OAH-OAMe-relative.pickle (will be created if missing)\n",
    "│   ├── PERT-bound-c.txt\n",
    "│   ├── PERT-bound.txt\n",
    "│   ├── PERT-combo.txt\n",
    "│   ├── PERT-hrex-c1.txt\n",
    "│   ├── PERT-hrex-c2.txt\n",
    "│   ├── PERT-hrex-c.txt\n",
    "│   ├── PERT-hrex.txt\n",
    "│   ├── SOMD-1.txt\n",
    "│   ├── SOMD-2.txt\n",
    "│   ├── SOMD-3.txt\n",
    "│   └── SOMD-4.txt\n",
    "├── SAMPL5-error-metrics.ipynb (this file)\n",
    "└── Exp\n",
    "    ├── CBClip.txt\n",
    "    ├── OAAllAvg.txt\n",
    "    ├── OAEnth10.txt\n",
    "    └── OASaltDep.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys,re\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib as mpl \n",
    "import matplotlib.pyplot as plt\n",
    "# Wrangle the data\n",
    "import pandas as pd\n",
    "# Nice figures\n",
    "import seaborn as sns\n",
    "# Access data\n",
    "import os\n",
    "# Save the results of bootstrapping\n",
    "import pickle\n",
    "\n",
    "%matplotlib inline\n",
    "# LaTeX\n",
    "mpl.rc('text', usetex=True)\n",
    "# amsmath for \\text{}\n",
    "# helvetic to for Helvetica font\n",
    "# sansmath to make math in Helvetica\n",
    "mpl.rcParams['text.latex.preamble'] = [\n",
    "       r'\\usepackage{amsmath}',\n",
    "       r'\\usepackage{helvet}',    \n",
    "       r'\\usepackage{sansmath}',  \n",
    "       r'\\sansmath',\n",
    "       r'\\renewcommand{\\familydefault}{\\sfdefault}',\n",
    "       r'\\usepackage[T1]{fontenc}',\n",
    "       r'\\usepackage{graphicx}'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function definitions for setting the error metrics, reading the data, performing bootstrap analysis, and plotting the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def geterrormetrics(x, y, Nm):\n",
    "    \"\"\"\n",
    "    Returns an array MTmp that stores the output of the error metrics on data given in (x, y).\n",
    "    Written by Niel.\n",
    "    \"\"\"\n",
    "    MTmp = np.zeros([Nm], np.float64)\n",
    "    # Slope, Intercept, R\n",
    "    Slp, MTmp[1], MTmp[2], pval, stderr = stats.linregress(x,y)\n",
    "    MTmp[0] = np.abs(1-Slp)\n",
    "    # R^2\n",
    "    MTmp[3] = MTmp[2]**2\n",
    "    # RMSE\n",
    "    MTmp[4] = np.sqrt(np.mean(((y - x)**2)))\n",
    "    # MSE\n",
    "    MTmp[5] = np.mean((y - x))\n",
    "    # MUE\n",
    "    MTmp[6] = np.mean(np.absolute(y - x))\n",
    "    # Tau\n",
    "    MTmp[7], prob = stats.kendalltau(x,y)\n",
    "    if np.isnan(MTmp[7]):\n",
    "        MTmp[7] = 0.0\n",
    "    return (MTmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### BootStrapping Definition\n",
    "def bootstrap(x, xsem, y, ysem, Nm, BootCyc, OAHOnly, OAMeOnly, CalcPairDiffs, CorrectOA, CorrectCB, WithUncert, WithRep):\n",
    "    \"\"\"\n",
    "    Performs bootstrap error anaysis on data (x, y) and errors (xsem, ysem) for a number\n",
    "    of bootstrapping cycles given by BootCyc. The remaining parameters specify subsets of calculations\n",
    "    that can be performed which are determined in the function `compute_bootstrap`.\n",
    "    Returns an array of values, uncertainties, and MBoot which holds an array of all values for\n",
    "    the error metrics for all bootstrapping cycles. \n",
    "    Written by Niel.\n",
    "    \"\"\"\n",
    "\n",
    "    MBoot = np.zeros([Nm,BootCyc], np.float64)\n",
    "    MVals = np.zeros([Nm], np.float64)\n",
    "    MSEMs = np.zeros([Nm], np.float64)\n",
    "    xtmp = np.zeros([len(x)], np.float64)\n",
    "    ytmp = np.zeros([len(x)], np.float64)\n",
    "    yfit = np.zeros([len(x)], np.float64)\n",
    "\n",
    "    for b in range(BootCyc):\n",
    "        for i in range(len(x)):\n",
    "\n",
    "          # Sample with/without replacement?\n",
    "          if WithRep:\n",
    "            j = np.random.randint(len(x))\n",
    "          else:\n",
    "            j = i\n",
    "\n",
    "          # Sampling Statistical Uncertainty\n",
    "          if not WithUncert or xsem[j] == 0.0:\n",
    "            xtmp[i] = x[j]\n",
    "          else:\n",
    "            xtmp[i] = np.random.normal(x[j],xsem[j])\n",
    "          if not WithUncert or ysem[j] == 0.0:\n",
    "            ytmp[i] = y[j]\n",
    "          else:\n",
    "            ytmp[i] = np.random.normal(y[j],ysem[j])\n",
    "\n",
    "          MBoot[0:Nm,b] = geterrormetrics(xtmp, ytmp, Nm)\n",
    "\n",
    "    for m in range(Nm):\n",
    "        MVals[m]=np.mean(MBoot[m])\n",
    "        MSEMs[m]=np.std(MBoot[m])\n",
    "\n",
    "    return (MVals,MSEMs,MBoot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_bootstrap(args):\n",
    "    \"\"\"\n",
    "    Read in data from disk given by `args`, convert to common units if necessary, \n",
    "    set calculation subsets, and call `bootstrap`.\n",
    "    Returns the number of calculations (i.e., the number of data files), the name of those files,\n",
    "    the raw (i.e., reported by submission) value of the error metrics, all bootstrapped values of the\n",
    "    error metrics, and all bootstrapped mean values.\n",
    "    Written by Niel.\n",
    "    \"\"\"\n",
    "\n",
    "    OAHOnly = False\n",
    "    OAMeOnly = False\n",
    "    CalcPairDiffs = False\n",
    "    CorrectOA = False\n",
    "    CorrectCB = False\n",
    "    WithUncert = True \n",
    "    WithRep = True  \n",
    "\n",
    "    ### Arguments: <Flags> <ExpType> <ExperimentFile> <CalculationFile1> [<CalculationFile2> ...]\n",
    "    ### Note, files should have the same number of data points\n",
    "    calcfiles=[]\n",
    "    for arg in args:\n",
    "      if arg == 'OAHOnly':\n",
    "        OAHOnly = True\n",
    "      if arg == 'OAMeOnly':\n",
    "        OAMeOnly = True\n",
    "      if arg == 'CalcPairDiffs':\n",
    "        CalcPairDiffs = True\n",
    "      if arg == 'CorrectOA':\n",
    "        CorrectOA = True\n",
    "      if arg == 'CorrectCB':\n",
    "        CorrectCB = True\n",
    "      if re.search(r'^(ka|dg|dh)$', arg):\n",
    "        exptype = arg\n",
    "      if re.search(r'\\.txt$', arg):\n",
    "        if re.search(r'Exp', arg):\n",
    "          expfile = arg\n",
    "        else:\n",
    "          calcfiles.append(arg)\n",
    "\n",
    "\n",
    "    ### Settings\n",
    "    R = 0.0019872036\n",
    "    T = 298.0\n",
    "    BootCyc = 100\n",
    "    MNames = ('Slope', 'Interc', 'R', 'R^2', 'RMSE', 'MSE', 'MUE', 'TAU')\n",
    "    Nm = len(MNames)\n",
    "    \n",
    "    ### Load experimental file and place data in array\n",
    "    print(expfile)\n",
    "    with open(expfile, 'r') as expraw:\n",
    "      explines = expraw.readlines()\n",
    "    exp = []\n",
    "    for line in explines:\n",
    "      if not re.match(r'^\\s*$', line):\n",
    "        exp.append(line.rstrip().replace('\\t', ' '))\n",
    "\n",
    "    ### If \"Only\" flag, just do first six, or last six\n",
    "    if OAHOnly:\n",
    "      exp = exp[0:6]\n",
    "    if OAMeOnly:\n",
    "      exp = exp[6:12]\n",
    "    if OAHOnly and OAMeOnly:\n",
    "      print(\"OAHOnly=True and OAMeOnly=True! Not compatible\")\n",
    "      exit()\n",
    "    N = len(exp)    # Number of data points\n",
    "    Np = (N-1)*N/2  # Number of data pairs\n",
    "\n",
    "    ### Are these binding constants or free energy (or enthalpy)? Convert.\n",
    "    emean = np.zeros([N], np.float64)\n",
    "    esem = np.zeros([N], np.float64)\n",
    "    for i in range(len(exp)):\n",
    "      cols = np.asarray(exp[i].split(), dtype=np.float64)\n",
    "      if exptype == 'ka':       \n",
    "        dG = -R*T*np.log(cols)\n",
    "        emean[i] = np.mean(dG)\n",
    "        esem[i] = np.std(dG, ddof=1)/np.sqrt(len(dG))\n",
    "      elif exptype == 'dg':\n",
    "        emean[i] = cols[0]\n",
    "        esem[i] = cols[1]\n",
    "      elif exptype == 'dh': \n",
    "        emean[i] = np.mean(cols)/1000\n",
    "        esem[i] = np.std(cols, ddof=1)/np.sqrt(len(cols))/1000\n",
    "      else:\n",
    "        print(exptype, \"... is not a valid experimental type\")\n",
    "\n",
    "    ### Calculate Experimental Pairwise Differences\n",
    "    if CalcPairDiffs:\n",
    "      h = 0\n",
    "      epmean = np.zeros([Np], np.float64)\n",
    "      epsem = np.zeros([Np], np.float64)\n",
    "      for i in range(len(exp)):\n",
    "        for j in range(i+1, len(exp)):\n",
    "          epmean[h] = emean[i] - emean[j]\n",
    "          epsem[h] = np.sqrt( esem[i]**2 + esem[j]**2 )\n",
    "          h += 1\n",
    "\n",
    "    ### Read in Calculated data.  \n",
    "    ### I should add a check to make sure number of data points is the same as experiment\n",
    "    Nc = len(calcfiles)\n",
    "    cmean = np.zeros([Nc,N], np.float64)\n",
    "    csem = np.zeros([Nc,N], np.float64)\n",
    "    if CalcPairDiffs:\n",
    "      cdmean = np.zeros([Nc,Nd], np.float64)\n",
    "      cdsem = np.zeros([Nc,Nd], np.float64)\n",
    "\n",
    "    RawMs = np.zeros([Nc,Nm], np.float64)\n",
    "    AllMBoot = np.zeros([Nc,Nm,BootCyc], np.float64)\n",
    "    AllMVals = np.zeros([Nc,Nm], np.float64)\n",
    "    AllMSEMs = np.zeros([Nc,Nm], np.float64)\n",
    "\n",
    "\n",
    "    nc = 0\n",
    "    for calcfile in calcfiles:\n",
    "      calc = np.loadtxt(calcfile, np.float64)\n",
    "      if OAHOnly:\n",
    "        calc = calc[0:6]\n",
    "      if OAMeOnly:\n",
    "        calc = calc[6:12]\n",
    "      for i in range(len(calc)):\n",
    "        if np.isscalar(calc[i]) == True:      ### If scalar instead of array; ie, no SEM given.\n",
    "          cmean[nc,i] = np.mean(calc[i])\n",
    "          csem[nc,i] = 0.0\n",
    "        else:                                 ### Assume Mean and SEM given\n",
    "          cmean[nc,i] = calc[i,0]\n",
    "          csem[nc,i] = calc[i,1]\n",
    "\n",
    "\n",
    "      ### Correct data set with MSE\n",
    "      if CorrectOA:\n",
    "        cmean[nc,0:6] = cmean[nc,0:6] - (np.mean(cmean[nc,0:6]) - np.mean(emean[0:6]))\n",
    "        if len(calc) == 12:\n",
    "          cmean[nc,6:12] = cmean[nc,6:12]- (np.mean(cmean[nc,6:12]) - np.mean(emean[6:12]))\n",
    "      if CorrectCB:\n",
    "        cmean[nc,0:10] = cmean[nc,0:10] - (np.mean(cmean[nc,0:10]) - np.mean(emean[0:10]))\n",
    "\n",
    "      if CalcPairDiffs:\n",
    "        h = 0\n",
    "        for i in range(len(calc)):\n",
    "          for j in range(i+1, len(calc)):\n",
    "            cpmean[nc,h] = cmean[nc,i] - cmean[nc,j]\n",
    "            cpsem[nc,h] = np.sqrt( csem[nc,i]**2 + csem[nc,j]**2 )\n",
    "            h += 1\n",
    "\n",
    "      RawMs[nc] = geterrormetrics(emean, cmean[nc], Nm)\n",
    "      AllMVals[nc],AllMSEMs[nc],AllMBoot[nc] = bootstrap(emean, esem, cmean[nc], csem[nc], \n",
    "                                                         Nm, BootCyc, OAHOnly, OAMeOnly, \n",
    "                                                         CalcPairDiffs, CorrectOA, CorrectCB, \n",
    "                                                         WithUncert, WithRep)\n",
    "      nc += 1\n",
    "    \n",
    "    CalcNames=[]\n",
    "    for name in calcfiles:\n",
    "      cols = name.split('.')\n",
    "      CalcNames.append(cols[0])\n",
    "\n",
    "    return(RawMs, AllMBoot, AllMVals, CalcNames, Nc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_summary_horizontal_narrow(Nc, RawMs, AllMBoot, AllMVals, CalcNames, absolute, relative, prefix, filename=None):\n",
    "    \"\"\"\n",
    "    Make a horizontal violin plot (methods on the y-axis) of the bootstrapped error metrics and save to disk.\n",
    "    Points are overlaid to represent the mean of each submission and lines are drawn\n",
    "    to shown the bootstrapped mean. For each error metric, a single graph is drawn:\n",
    "    RMSE, slope, R squared, and Kendall tau. There is manual tweaking of names, labels,\n",
    "    and colors.\n",
    "    v2: The aspect ratio is changed to make the plots a bit more narrow and long.\n",
    "    v3: Order first by reported mean, then bootstrapped mean for rounded values.\n",
    "    v3: 'Slope' goes to 'm' and 'Tau' goes to '\\tau'\n",
    "    v3: Increase grid thickness\n",
    "    v3: KDE bandwidth of 0.2 to reduce some jitteriness in the discrete tau values.\n",
    "    Also, bigger font size.\n",
    "    The figures are saved given by the parameter `filename`.\n",
    "    \"\"\"\n",
    "\n",
    "    # Set the graph labels to different for absolute and relative calculations.\n",
    "    if absolute:\n",
    "        calculation_name = [\"RMSE (kcal/mol)\", \"Abs(1-m)\", \"$R^{2}$\", \"$\\tau$\"]\n",
    "    if relative:\n",
    "        calculation_name = [\"RMSE_c (kcal/mol)\", \"Abs(1-m_c)\", \"$R^{2}$_c\", \"$\\tau$_c\"]\n",
    "    calculation_index = [4, 0, 3, 7] # From Niel's MTmp\n",
    "    \n",
    "    for i in calculation_index:\n",
    "        tmp = np.argsort(RawMs[0:Nc,i])\n",
    "        Order = [j for j in tmp]\n",
    "        print('Calculation = {}, best method index = {}, best method name = {}'.format(i, \n",
    "                                                                                       np.argsort(RawMs[0:Nc,i])[0], \n",
    "                                                                                       CalcNames[np.argsort(RawMs[0:Nc,i])[0]]))\n",
    "        \n",
    "        # Order first by reported mean, then by bootstrapped distribution mean.\n",
    "        round_RawMs = np.around(RawMs[:,i], 2)\n",
    "        round_AllMVals = np.around(AllMVals[:,i], 2)\n",
    "        rounds = pd.DataFrame()\n",
    "        rounds['b'] = AllMVals[:, i]\n",
    "        rounds['r'] = round_RawMs\n",
    "        rounds['o'] = range(len(round_AllMVals))\n",
    "        rounds['m'] = [CalcNames[i] for i in range(len(AllMVals))]\n",
    "        # Reorder array based on raw value first, then mean of the boostrapped distribution.\n",
    "        ordered = rounds.sort_values(['r', 'b'], inplace=False)\n",
    "        # Grab the values of the third column, which was original order, based on \n",
    "        # values of first two columns.\n",
    "        Order = ordered['o'].as_matrix()        \n",
    "        # For R squared and Tau reverse the ordering so the graphs always present best to worst case \n",
    "        # (left to right or top to bottom).\n",
    "        if calculation_name[calculation_index.index(i)] == '$R^{2}$' \\\n",
    "        or calculation_name[calculation_index.index(i)] == '$\\tau$' or \\\n",
    "        calculation_name[calculation_index.index(i)] == '$R^{2}$_c' or \\\n",
    "        calculation_name[calculation_index.index(i)] == '$\\tau$_c':  \n",
    "            Order = ordered['o'].as_matrix()[::-1]\n",
    "            \n",
    "        # Cleanup submission names grabbed from the filenames.        \n",
    "        CalcNames=['TI/BAR' if i == 'TIxBar' else i for i in CalcNames]\n",
    "        CalcNames=['MovTyp-1*' if i == 'MovTyp-1' else i for i in CalcNames] \n",
    "        CalcNames=['MovTyp-2*' if i == 'MovTyp-2' else i for i in CalcNames] \n",
    "        CalcNames=['Null1*' if i == 'Null1' else i for i in CalcNames] \n",
    "        CalcNames=['DFT-neutral*' if i == 'DFT-neutral' else i for i in CalcNames] \n",
    "        CalcNames=['DFT-charged*' if i == 'DFT-charged' else i for i in CalcNames] \n",
    "        CalcNames=['CCSD(T)-neutral*' if i == 'CCSD(T)-neutral' else i for i in CalcNames]\n",
    "        \n",
    "        # Exclude Null1 model from Tau calculation and plotting.\n",
    "        if i == 7 and absolute == True:\n",
    "            # Exclude Null1 model from Tau calculation and plotting.\n",
    "            element_to_remove = np.where([CalcNames[i] == 'Null1*' for i in Order])[0][0]\n",
    "            Order_without_null1 = np.delete(Order, element_to_remove)\n",
    "            Order = np.copy(Order_without_null1)\n",
    "\n",
    "        # Wrangle the data into a `DataFrame` so we can do categorical plotting with seaborn.\n",
    "        # The bootstrapped error distributions.\n",
    "        df = pd.DataFrame()\n",
    "        df['AllMBoot'] = np.hstack(([AllMBoot[n,i] for n in Order]))\n",
    "        df['Method'] = np.hstack(([np.repeat(CalcNames[n], len(AllMBoot[n,i]) ) for n in Order]))\n",
    "        # The 'raw' (i.e., submitted) values for the error metrics.\n",
    "        df2 = pd.DataFrame()\n",
    "        df2['RawMs'] = [RawMs[n,i] for n in Order]\n",
    "        df2['Method'] = [CalcNames[n] for n in Order]\n",
    "        # The bootstrapped error means.\n",
    "        df3 = pd.DataFrame()\n",
    "        df3['AllMVals'] = [AllMVals[n,i] for n in Order]\n",
    "        df3['Method'] = [CalcNames[n] for n in Order]\n",
    "        # Set axes labels for the submissions.\n",
    "        labels = [CalcNames[n] for n in Order]\n",
    "        # Blue for everything except red for null models.\n",
    "        palette = ['#4169e1' if i != 'Null1*' and i != 'Null2' else '#fa8072' for i in labels]\n",
    "        \n",
    "        # Set up plot aesthetics.\n",
    "        sns.set_style(\"whitegrid\", rc={'legend.frameon': False})\n",
    "        sns.set_context(\"paper\", font_scale=1.0, rc={\"lines.linewidth\": 2.5, 'legend.frameon': False})\n",
    "        sns.despine(left=True, bottom=True, right=True, top=True)\n",
    "        fig, ax = plt.subplots(1, figsize=(2.400,5.673), dpi=300)\n",
    "        ax.grid(linewidth = 1.0)\n",
    "        g = sns.violinplot(y = 'Method', x = 'AllMBoot', data=df, inner=None, linewidth=0, palette=palette, cut = 0, \n",
    "                           orientation='h', split=True, scale='width', gridsize=400, bw=0.2)\n",
    "\n",
    "        for n in Order:\n",
    "            # Plot the 'raw' (submitted) values for the error metrics as white circles with a black border\n",
    "            ax.scatter(y = np.where(Order == n)[0], x = df2[df2['Method'] == CalcNames[n]]['RawMs'], s = 8, marker = 'o', \n",
    "                       color = 'w', edgecolor = 'k', linewidth = 0.3, zorder = 21)\n",
    "            # Plot the bootstrapped mean values as a line.\n",
    "            # This gets the column position because we are plotting using `Order` and the width of the line is 1/len(CalcNames).\n",
    "            # We could shorten the line a little bit for better readability.\n",
    "            ax.axvline(x = AllMVals[n, i], ymin = 1 - (np.where(Order == n)[0] / len(Order) + 0.01), \n",
    "                       ymax = 1 - (np.where(Order == n)[0] / len(Order) + 1/len(Order) - 0.01), \n",
    "                       linewidth=2, c='k', lw = 1, zorder=20, alpha=0.5)\n",
    "            # This adds a bit of a white background around the lines by plotting underneath a slightly larger line.\n",
    "            ax.axvline(x = AllMVals[n, i], ymin = 1 - (np.where(Order == n)[0] / len(Order) + 0.01), \n",
    "                       ymax = 1 - (np.where(Order == n)[0] / len(Order) + 1/len(Order) - 0.01), \n",
    "                       linewidth=2, c='w', lw = 1.3, zorder=19, alpha=1.0)\n",
    "                        \n",
    "        plt.xlabel(calculation_name[calculation_index.index(i)], labelpad = 1)\n",
    "        plt.ylabel('')\n",
    "        # Let's limit slope and R^2 for better aesthetics.\n",
    "        if calculation_name[calculation_index.index(i)] == '$R^{2}$' or \\\n",
    "        calculation_name[calculation_index.index(i)] == '$R^{2}$_c':\n",
    "            ax.set_xlim([0, 1])\n",
    "        # Let's limit for Tau, too:\n",
    "        if calculation_name[calculation_index.index(i)] == '$\\tau$' or \\\n",
    "        calculation_name[calculation_index.index(i)] == '$\\tau$_c':\n",
    "            ax.set_xlim([-1.0, 1.0])\n",
    "        # Fix the lower limit only for the Abs(1-slope) aesthetic.\n",
    "        if calculation_name[calculation_index.index(i)] == 'Abs(1-m)' or \\\n",
    "        calculation_name[calculation_index.index(i)] == 'Abs(1-m_c)':\n",
    "            ax.set_xlim([0, 6])\n",
    "        if prefix != 'CBClip': \n",
    "            if calculation_name[calculation_index.index(i)] == 'RMSE (kcal/mol)' or \\\n",
    "        calculation_name[calculation_index.index(i)] == 'RMSE_c (kcal/mol)':\n",
    "                ax.set_xlim([0, 14])\n",
    "        else: \n",
    "            if calculation_name[calculation_index.index(i)] == 'RMSE (kcal/mol)' or \\\n",
    "        calculation_name[calculation_index.index(i)] == 'RMSE_c (kcal/mol)':\n",
    "                ax.set_xlim([0, np.max(df2['RawMs'])+0.5*np.max(df2['RawMs'])])\n",
    "\n",
    "        # Because LaTeX rendering, we have to escape these underscores...\n",
    "        if i == 0:\n",
    "            if relative:\n",
    "                latex_label = 'Abs(1-$\\\\text{m}_{\\\\text{c}}$)'\n",
    "            if absolute:\n",
    "                latex_label = 'Abs(1-m)'\n",
    "        if i == 4:\n",
    "            if relative:\n",
    "                latex_label = '$\\\\text{RMSE}_{\\\\text{c}}$ (kcal/mol)'\n",
    "            if absolute:\n",
    "                latex_label = 'RMSE (kcal/mol)'\n",
    "        if i == 3:\n",
    "            if relative:\n",
    "                latex_label = '$\\\\text{R}^{\\\\text{2}}_{\\\\text{c}}$'\n",
    "            if absolute:\n",
    "                latex_label = '$\\\\text{R}^{\\\\text{2}}$'\n",
    "        if i == 7:\n",
    "            if relative:\n",
    "                latex_label = '$\\\\tau_{\\\\text{c}}$'\n",
    "            if absolute:\n",
    "                latex_label = '$\\\\tau$'\n",
    "    \n",
    "        plt.xlabel(latex_label)\n",
    "        plt.title(prefix)\n",
    "\n",
    "        if filename:\n",
    "            if i == 0:\n",
    "                label = 'slope'\n",
    "            if i == 4:\n",
    "                label = 'rmse'\n",
    "            if i == 3:\n",
    "                label = 'r-squared'\n",
    "            if i == 7:\n",
    "                label = 'tau'\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(filename + '-' + str(label) + '-narrow.png', dpi=300, bbox_inches='tight', pad_inches=0.04) #or .pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculations and plotting!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "run_location = '/path/to/SAMPL5-bootstrapping-error-analysis'\n",
    "run_calculation = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#SaltDep-Abs\n",
    "os.chdir(run_location+'/Calc-OA')\n",
    "string = 'ka ../Exp/OASaltDep.txt Null1.txt Null2.txt APR-OPC.txt APR-TIP3P.txt BEDAM.txt Metadynamics.txt MMPBSA-GAFF.txt MovTyp-1.txt MovTyp-2.txt PERT-bound-c.txt PERT-bound.txt PERT-hrex-c1.txt PERT-hrex-c2.txt PERT-hrex-c.txt PERT-hrex.txt SOMD-1.txt SOMD-2.txt SOMD-3.txt SOMD-4.txt'\n",
    "args = string.split()\n",
    "if run_calculation:\n",
    "    RawMs, AllMBoot, AllMVals, CalcNames, Nc = compute_bootstrap(args)\n",
    "    results = [RawMs, AllMBoot, AllMVals, CalcNames, Nc]\n",
    "    pickle.dump(results, open('OAH-OAMe-absolute.pickle', 'wb'))\n",
    "results = pickle.load( open('OAH-OAMe-absolute.pickle', 'rb'))\n",
    "RawMs, AllMBoot, AllMVals, CalcNames, Nc = results\n",
    "plot_summary_horizontal_narrow(Nc, RawMs, AllMBoot, AllMVals, CalcNames, absolute=True, relative=False, prefix='OAH/OAMe', filename='OAH-OAMe-absolute')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#SaltDep-RelCor\n",
    "os.chdir(run_location+'/Calc-OA')\n",
    "string = 'CorrectOA ka ../Exp/OASaltDep.txt Null1.txt Null2.txt APR-OPC.txt APR-TIP3P.txt BEDAM.txt CCSD(T)-neutral.txt DFT-charged.txt DFT-neutral.txt Metadynamics.txt MMPBSA-GAFF.txt MovTyp-1.txt MovTyp-2.txt PERT-bound-c.txt PERT-bound.txt PERT-hrex-c1.txt PERT-hrex-c2.txt PERT-hrex-c.txt PERT-hrex.txt SOMD-1.txt SOMD-2.txt SOMD-3.txt SOMD-4.txt'\n",
    "args = string.split()\n",
    "if run_calculation:\n",
    "    RawMs, AllMBoot, AllMVals, CalcNames, Nc = compute_bootstrap(args)\n",
    "    results = [RawMs, AllMBoot, AllMVals, CalcNames, Nc]\n",
    "    pickle.dump(results, open('OAH-OAMe-relative.pickle', 'wb'))\n",
    "results = pickle.load( open('OAH-OAMe-relative.pickle', 'rb'))\n",
    "RawMs, AllMBoot, AllMVals, CalcNames, Nc = results\n",
    "plot_summary_horizontal_narrow(Nc, RawMs, AllMBoot, AllMVals, CalcNames, absolute=False, relative=True, prefix='OAH/OAMe', filename='OAH-OAMe-relative')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#CBClip-Abs\n",
    "os.chdir(run_location+'/Calc-CB')\n",
    "string = 'ka ../Exp/CBClip.txt Null1.txt Null2.txt BAR-ab-initio.txt BAR-dock.txt BEDAM.txt MovTyp-1.txt MovTyp-2.txt SOMD-1.txt SOMD-2.txt SOMD-3.txt SOMD-4.txt TI-ab-initio.txt TI-dock.txt TIxBar.txt'\n",
    "args = string.split()\n",
    "if run_calculation:\n",
    "    RawMs, AllMBoot, AllMVals, CalcNames, Nc = compute_bootstrap(args)\n",
    "    results = [RawMs, AllMBoot, AllMVals, CalcNames, Nc]\n",
    "    pickle.dump(results, open('CBClip-absolute.pickle', 'wb'))\n",
    "results = pickle.load( open('CBClip-absolute.pickle', 'rb'))\n",
    "RawMs, AllMBoot, AllMVals, CalcNames, Nc = results\n",
    "plot_summary_horizontal_narrow(Nc, RawMs, AllMBoot, AllMVals, CalcNames, absolute=True, relative=False, prefix='CBClip', filename='CBClip-absolute')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
